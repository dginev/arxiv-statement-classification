{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Trail\n",
    "\n",
    "## Classification Benchmarks\n",
    "\n",
    "\n",
    "### Full, 50 class task (pre-analysis, 10.5 million paragraphs)\n",
    "\n",
    "|Measure              | F1 score | F1 (no math) |\n",
    "|:--------------------|---------:|-------------:|\n",
    "| Zero Rule           |  0.201   | 0.206        |\n",
    "| 3-level BiLSTM      |   0.67   |      0.67    |\n",
    "\n",
    "### Core, 13 class task (10.4 million paragraphs)\n",
    "\n",
    "|Measure         | F1 score | F1 (no math) |\n",
    "|:---------------|---------:|-------------:|\n",
    "| Zero Rule      |    0.388 |        0.369 |\n",
    "| LogReg         |     0.30 |        0.35  |\n",
    "| LogReg + GloVe |     0.77 |        0.77  |\n",
    "| Perceptron     |     0.83 |        0.83  |\n",
    "| HAN            |     0.89 |        0.88  |\n",
    "| 3-level BiLSTM |   0.91   |        0.90  |\n",
    "\n",
    "\n",
    "**Legend:**\n",
    " 1. Zero Rule - a trivial analytic model with a single constant prediction -- the most common class in the dataset\n",
    " 2. LogReg - logistic regression with raw word indexes, where each paragraph is an array of 480 integers\n",
    " 3. Logreg + Glove - logistic regression on arXMLiv 08.2018 word embeddings, each paragraph is a (480,300) matrix of integers\n",
    " 4. Perceptron - one hidden fully-connected layer of neurons, with a final softmax layer. Also based on the GloVe-embedded (480,300) data\n",
    " 5. HAN - Hierarchical Attention Networks, split 8 sentences of 60 words each. Also uses GloVe embeddings, for embedded paragraph shape of (8,60,300). Size established with grid search on 3% of the data.\n",
    " 6. BiLSTM - encoder/decoder BiLSTM pair with a LSTM follow-up. BiLSTM(128)→BiLSTM(64)→LSTM(64)→Dense(13)\n",
    "\n",
    "**Math-free control experiment:** \n",
    " 1. All mathematics is stripped out, instead of being normalized as math lexemes\n",
    " 2. Regenerated GloVe model, (vocabulary size reduces from just over 1 million to 0.75 million words)\n",
    " 3. Re-extracted paragraph dataset (unique SHA256 names reduce data from 10.5 to 10.1 million paragraphs)\n",
    " 4. Confirmed 50-class pre-analysis confusion matrix is analogous, reduced to 13-class task (10 million paragraphs)\n",
    " 5. Re-ran all 13-class model training notebooks on math-free data, to co-report and measure effect of math modality\n",
    " \n",
    "*Inescapable control impurity:* we need to run the *identical* models to have a claim of comparison, but the average length of a paragraph is significantly lower with math omitted. Additionally, ~10% of the paragraphs exceed the 480 word cap, and stripping the math leads to including more content from the extra long items. This offers additional context to the control models, which was never visible to the math-lexeme-enabled models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **Final assembly**: 25 of the original classes grouped into 13 strongly separable unions:\n",
    "\n",
    "| Class           | Additional Members | Frequency |\n",
    "|:----------------|:-------------------|----------:|\n",
    "| abstract        | -                  | 1,030,774 |\n",
    "| acknowledgement | -                  |   162,230 |\n",
    "| conclusion      | discussion         |   401,235 |\n",
    "| definition      | -                  |   686,717 |\n",
    "| example         | -                  |   295,152 |\n",
    "| introduction    | -                  |   688,530 |\n",
    "| keywords        | -                  |     1,565 |\n",
    "| proof           | demonstration      | 2,148,793 |\n",
    "| proposition     | assumption, claim, | 4,060,029 |\n",
    "| +               | condition,         |         + |\n",
    "| +               | conjecture,        |         + |\n",
    "| +               | corollary, fact,   |         + |\n",
    "| +               | lemma, theorem     |         + |           \n",
    "| problem         | question           |    57,609 |\n",
    "| related work    | -                  |    26,299 |\n",
    "| remark          | note               |   643,500 |\n",
    "| result          | -                  |   239,931 |\n",
    "\n",
    "\n",
    "  Dropped (25) =\n",
    "  notice, expansion, hint, expectation, explanation, affirmation, answer, issue, bound, summary, experiment,\n",
    "  solution, criterion, principle, comment, exercise, constraint, rule, convention, case, step, overview, notation, observation, method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-analysis 50-class task, BiLSTM\n",
    "\n",
    "![normalized 50 class confusion matrix](https://github.com/dginev/arxiv-ams-paragraph-classification/blob/49-class-dataset/figures/confusion_matrix_normalized_50class.png?raw=true)\n",
    "\n",
    "# Core 13-class task, BiLSTM\n",
    "\n",
    "![normalized 13 class confusion matrix](https://github.com/dginev/arxiv-ams-paragraph-classification/blob/49-class-dataset/figures/confusion_matrix_normalized_13class.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
